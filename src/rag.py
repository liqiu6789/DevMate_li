import os
import shutil
from langchain_community.document_loaders import DirectoryLoader, TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma
from src.config import settings

# å®šä¹‰å‘é‡æ•°æ®åº“çš„æŒä¹…åŒ–è·¯å¾„
PERSIST_DIRECTORY = "./chroma_db"

def ingest_docs():
    """è¯»å– docs/ ç›®å½•ä¸‹çš„æ–‡æ¡£å¹¶å­˜å…¥å‘é‡æ•°æ®åº“"""
    
    # 1. æ£€æŸ¥æ–‡æ¡£ç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists("docs"):
        print("âŒ ç›®å½• 'docs' ä¸å­˜åœ¨ï¼Œè¯·å…ˆåˆ›å»ºå¹¶æ”¾å…¥æ–‡æ¡£ã€‚")
        return

    # 2. åŠ è½½æ–‡æ¡£
    print("ğŸ“‚ Loading documents...")
    loader = DirectoryLoader("docs", glob="**/*.md", loader_cls=TextLoader, loader_kwargs={"encoding": "utf-8"})
    docs = loader.load()
    print(f"   Found {len(docs)} documents.")

    if not docs:
        return

    # 3. åˆ‡åˆ†æ–‡æ¡£
    print("âœ‚ï¸ Splitting documents...")
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200
    )
    splits = text_splitter.split_documents(docs)
    print(f"   Split into {len(splits)} chunks.")

    # 4. åˆå§‹åŒ– Embedding æ¨¡å‹
    embeddings = OpenAIEmbeddings(
        base_url=settings.AI_BASE_URL,
        api_key=settings.API_KEY,
        model=settings.EMBEDDING_MODEL_NAME
    )

    # 5. å­˜å…¥ ChromaDB
    # å¦‚æœæ•°æ®åº“å·²å­˜åœ¨ï¼Œå…ˆæ¸…ç©ºä»¥ä¾¿é‡æ–°ç´¢å¼•ï¼ˆå¯é€‰ï¼Œå¼€å‘é˜¶æ®µæ–¹ä¾¿ï¼‰
    if os.path.exists(PERSIST_DIRECTORY):
        shutil.rmtree(PERSIST_DIRECTORY)
        print("   Cleared existing database.")

    print("ğŸ’¾ Saving to vector database...")
    vectorstore = Chroma.from_documents(
        documents=splits,
        embedding=embeddings,
        persist_directory=PERSIST_DIRECTORY
    )
    print("âœ… Ingestion complete!")

def query_knowledge_base(query: str, k: int = 2):
    """
    æŸ¥è¯¢å‘é‡æ•°æ®åº“
    :param query: ç”¨æˆ·é—®é¢˜
    :param k: è¿”å›æœ€ç›¸å…³çš„æ–‡æ¡£å—æ•°é‡
    :return: ç›¸å…³çš„æ–‡æ¡£åˆ—è¡¨
    """
    embeddings = OpenAIEmbeddings(
        base_url=settings.AI_BASE_URL,
        api_key=settings.API_KEY,
        model=settings.EMBEDDING_MODEL_NAME
    )
    
    # åŠ è½½å·²å­˜åœ¨çš„æ•°æ®åº“
    vectorstore = Chroma(
        persist_directory=PERSIST_DIRECTORY,
        embedding_function=embeddings
    )
    
    print(f"\nğŸ” Searching for: '{query}'")
    results = vectorstore.similarity_search(query, k=k)
    
    return results

# --- æµ‹è¯•ä»£ç  ---
if __name__ == "__main__":
    # 1. å…ˆæ‰§è¡Œæ‘„å…¥ï¼ˆå¦‚æœå·²ç»æ‘„å…¥è¿‡ï¼Œè¿™æ­¥å¯ä»¥æ³¨é‡Šæ‰ï¼‰
    ingest_docs()
    
    # 2. æµ‹è¯•æŸ¥è¯¢
    test_query = "å˜é‡å‘½åæœ‰ä»€ä¹ˆè¦æ±‚ï¼Ÿ"
    hits = query_knowledge_base(test_query)
    
    print("\nğŸ“ Search Results:")
    for i, doc in enumerate(hits):
        print(f"--- Result {i+1} ---")
        print(doc.page_content)
        print("------------------")